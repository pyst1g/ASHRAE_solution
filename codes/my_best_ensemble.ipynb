{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:17:39.558283Z",
     "start_time": "2020-01-13T14:17:33.655942Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:18:10.291531Z",
     "start_time": "2020-01-13T14:17:39.562609Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# leaked_df = pd.read_csv('../input/leaked_data_all.csv', parse_dates=['timestamp'])\n",
    "with open('../input/leak_data_drop_bad_rows.pkl', 'rb') as f:\n",
    "    leaked_df = pickle.load(f).rename(columns={'meter_reading': 'leaked_meter_reading'})\n",
    "\n",
    "# leaked_df = pd.read_feather('../input/leak_data.feather').rename(columns={'meter_reading': 'leaked_meter_reading'})\n",
    "leaked_df = leaked_df[['building_id','meter','timestamp', 'leaked_meter_reading']]\n",
    "leaked_df = leaked_df.query('timestamp>=20170101')\n",
    "\n",
    "building_meta = pd.read_csv(\"../input/building_metadata.csv\")\n",
    "\n",
    "leaked_df = leaked_df.merge(building_meta[['building_id', 'site_id']], on='building_id', how='left')\n",
    "\n",
    "leaked_df = leaked_df.query('~(meter==0 & site_id==0)')\n",
    "# leaked_df = leaked_df.query('site_id==[2,4,15]')\n",
    "# leaked_df = leaked_df.query('105<=building_id<=564 | 656<=building_id')\n",
    "\n",
    "test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:23.224574Z",
     "start_time": "2020-01-13T14:18:10.303370Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../output/use_train_fe_seed1_leave31_lr001_mul05.csv' does not exist: b'../output/use_train_fe_seed1_leave31_lr001_mul05.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-218845814c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mleave\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m63\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"001\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"005\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"01\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msubmission_s1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../output/use_train_fe_seed1_leave{leave}_lr{lr}_mul05.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#         submission_s2 = pd.read_csv(f'../output/use_train_fe_seed2_leave{leave}_lr{lr}_mul05.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         submission_s3 = pd.read_csv(f'../output/use_train_fe_seed3_leave{leave}_lr{lr}_mul05.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dirac/sano/env36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dirac/sano/env36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dirac/sano/env36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dirac/sano/env36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/dirac/sano/env36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../output/use_train_fe_seed1_leave31_lr001_mul05.csv' does not exist: b'../output/use_train_fe_seed1_leave31_lr001_mul05.csv'"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "for leave in [7,15,31, 63]:\n",
    "    for lr in [\"001\",\"005\",\"01\"]:\n",
    "        submission_s1 = pd.read_csv(f'../output/use_train_fe_seed1_leave{leave}_lr{lr}_mul05.csv')\n",
    "#         submission_s2 = pd.read_csv(f'../output/use_train_fe_seed2_leave{leave}_lr{lr}_mul05.csv')\n",
    "#         submission_s3 = pd.read_csv(f'../output/use_train_fe_seed3_leave{leave}_lr{lr}_mul05.csv')\n",
    "#         test[f'pred{i}'] = (submission_s1['meter_reading'] + submission_s2['meter_reading'] + submission_s3['meter_reading']) / 3\n",
    "        test[f'pred{i}'] = submission_s1['meter_reading']\n",
    "        i += 1\n",
    "# del submission_s1, submission_s2, submission_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:27.387076Z",
     "start_time": "2020-01-13T14:19:27.383546Z"
    }
   },
   "outputs": [],
   "source": [
    "# submission11 = pd.read_csv('../output/fe2_lgbm.csv')\n",
    "# submission12 = pd.read_csv('../output/submission_tomioka.csv')\n",
    "# submission13 = pd.read_csv('../output/submission_half_and_half.csv')\n",
    "# submission14 = pd.read_csv('../output/submission_distill.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:27.553471Z",
     "start_time": "2020-01-13T14:19:27.549264Z"
    }
   },
   "outputs": [],
   "source": [
    "# test['pred11'] = np.exp(1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:48.950281Z",
     "start_time": "2020-01-13T14:19:27.685686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "test = test.merge(leaked_df, on=['building_id', 'meter', 'timestamp'], how='left')\n",
    "N = test.columns.str.startswith('pred').sum()\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:54.388676Z",
     "start_time": "2020-01-13T14:19:48.953030Z"
    }
   },
   "outputs": [],
   "source": [
    "test_sub = test.copy()\n",
    "test = test[~test['leaked_meter_reading'].isnull()]\n",
    "test2017 = test.query('timestamp<20180101')\n",
    "test2018 = test.query('20180101<=timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:59.019218Z",
     "start_time": "2020-01-13T14:19:54.390443Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.8865035729434979\n",
      "2 0.8027040608088559\n",
      "3 0.7986760807250235\n",
      "4 0.8591574841491776\n",
      "5 0.7981638094671428\n",
      "6 0.7967608101420031\n",
      "\n",
      "1 0.8952273203538572\n",
      "2 0.7829052029232684\n",
      "3 0.7741473995216276\n",
      "4 0.855230482461891\n",
      "5 0.7707523357204036\n",
      "6 0.7661268767700412\n",
      "\n",
      "1 0.8909050023878055\n",
      "2 0.7928008966593048\n",
      "3 0.7864261757027987\n",
      "4 0.8571832324742487\n",
      "5 0.7844870622737529\n",
      "6 0.781492547072532\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,N+1):\n",
    "    print(i, np.sqrt(mean_squared_error(np.log1p(test2018['leaked_meter_reading']), np.log1p(test2018[f'pred{i}']))))\n",
    "\n",
    "print()\n",
    "\n",
    "for i in range(1,N+1):\n",
    "    print(i, np.sqrt(mean_squared_error(np.log1p(test2017['leaked_meter_reading']), np.log1p(test2017[f'pred{i}']))))\n",
    "\n",
    "print()\n",
    "    \n",
    "for i in range(1,N+1):\n",
    "    print(i, np.sqrt(mean_squared_error(np.log1p(test['leaked_meter_reading']), np.log1p(test[f'pred{i}']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:59.023668Z",
     "start_time": "2020-01-13T14:19:59.021011Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sid = 1\n",
    "# for i in range(1,N+1):\n",
    "#     print(i, np.sqrt(mean_squared_error(np.log1p(test2018.query(f'meter==0 & site_id=={sid}')['leaked_meter_reading']), \n",
    "#                                         np.log1p(test2018.query(f'meter==0 & site_id=={sid}')[f'pred{i}']))))\n",
    "\n",
    "# print()\n",
    "\n",
    "# for i in range(1,N+1):\n",
    "#     print(i, np.sqrt(mean_squared_error(np.log1p(test2017.query(f'meter==0 & site_id=={sid}')['leaked_meter_reading']), \n",
    "#                                         np.log1p(test2017.query(f'meter==0 & site_id=={sid}')[f'pred{i}']))))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:59.103223Z",
     "start_time": "2020-01-13T14:19:59.026499Z"
    }
   },
   "outputs": [],
   "source": [
    "focus_df = test2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:59.163124Z",
     "start_time": "2020-01-13T14:19:59.105040Z"
    }
   },
   "outputs": [],
   "source": [
    "def preproceeding(submission, N):\n",
    "    submission.loc[:,'pred1':'leaked_meter_reading'] = np.log1p(submission.loc[:,'pred1':'leaked_meter_reading'])\n",
    "    g = submission.groupby('meter')\n",
    "    sub_sub = [dict(), dict(), dict(), dict()]\n",
    "    leak_sub = [dict(), dict(), dict(), dict()]\n",
    "    leak_leak = [0,0,0,0]\n",
    "    \n",
    "    for meter in [3,2,1,0]:\n",
    "        for i in tqdm(range(1,N+1)):\n",
    "            leak_sub[meter][i] = sum(-2 * g.get_group(meter)['leaked_meter_reading'] * g.get_group(meter)[f'pred{i}'])\n",
    "            for j in range(1,N+1):\n",
    "                if i > j: \n",
    "                    sub_sub[meter][(i,j)] = sub_sub[meter][(j,i)]\n",
    "                else:\n",
    "                    sub_sub[meter][(i,j)] = sum(g.get_group(meter)[f'pred{i}'] * g.get_group(meter)[f'pred{j}'])\n",
    "        \n",
    "        leak_leak[meter] = (sum(g.get_group(meter)['leaked_meter_reading'] ** 2))\n",
    "    \n",
    "    return sub_sub, leak_sub, leak_leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:20:25.401496Z",
     "start_time": "2020-01-13T14:19:59.165295Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.42it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  3.27it/s]\n",
      "100%|██████████| 6/6 [00:06<00:00,  1.14s/it]\n",
      "100%|██████████| 6/6 [00:13<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "sub_sub, leak_sub, leak_leak = preproceeding(focus_df.copy(), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:20:25.411291Z",
     "start_time": "2020-01-13T14:20:25.405477Z"
    }
   },
   "outputs": [],
   "source": [
    "count_itr = 0\n",
    "def optimization(meter, sub_sub, leak_sub, leak_leak, length, W):\n",
    "    \n",
    "#     global count_itr\n",
    "#     if count_itr%1000 == 0: print(count_itr, end=' ')\n",
    "#     count_itr += 1\n",
    "    \n",
    "    loss_total = 0\n",
    "\n",
    "    for i, a in enumerate(W, 1):\n",
    "        for j, b in enumerate(W, 1):\n",
    "            loss_total += a * b * sub_sub[meter][(i, j)]\n",
    "\n",
    "    for i, a in enumerate(W, 1):\n",
    "        loss_total += leak_sub[meter][i] * a\n",
    "\n",
    "    loss_total += leak_leak[meter]\n",
    "    \n",
    "    return np.sqrt(loss_total / length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:20:54.904979Z",
     "start_time": "2020-01-13T14:20:25.413036Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:07<00:00, 13894.04it/s]\n",
      "100%|██████████| 100000/100000 [00:06<00:00, 14755.20it/s]\n",
      "100%|██████████| 100000/100000 [00:08<00:00, 12138.75it/s]\n",
      "100%|██████████| 100000/100000 [00:06<00:00, 15444.24it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "score = [list(), list(), list(), list()]\n",
    "weight = [list(), list(), list(), list()]\n",
    "\n",
    "for meter in [0,1,2,3]:\n",
    "    f = partial(optimization, meter, sub_sub, leak_sub, leak_leak, len(focus_df.query(f'meter=={meter}')))\n",
    "    for i in tqdm(range(100000)):\n",
    "        W = np.random.rand(N)\n",
    "\n",
    "        to_zero = np.arange(N)\n",
    "        np.random.shuffle(to_zero)\n",
    "\n",
    "        W[to_zero[:np.random.randint(N)]] = 0\n",
    "        W /= W.sum()\n",
    "        W *= np.random.rand() * 0.3 + 0.8\n",
    "        score[meter].append(f(W))\n",
    "        weight[meter].append(W)\n",
    "    \n",
    "    score[meter] = np.array(score[meter])\n",
    "    weight[meter] = np.array(weight[meter])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:20:54.910095Z",
     "start_time": "2020-01-13T14:20:54.906756Z"
    }
   },
   "outputs": [],
   "source": [
    "# 今までのbest_score\n",
    "# 0\n",
    "# 0.6457341965029569 # 2,4,15\n",
    "# 0.7670864405850898 # 1,2,15\n",
    "\n",
    "# 1\n",
    "# 1.1028821246797627\n",
    "\n",
    "# 2\n",
    "# 0.9266132278805228\n",
    "\n",
    "# 3\n",
    "# 1.1595900581550331\n",
    "\n",
    "\n",
    "# new leak set\n",
    "# 0.7229769339789924\n",
    "# 1.4360871220006104\n",
    "# 0.9269688704973097\n",
    "# 1.1567657302973289\n",
    "\n",
    "# 0.723733378801817\n",
    "# 1.4325472242980108\n",
    "# 0.9270139246582472\n",
    "# 1.1560000215450374\n",
    "\n",
    "# 0.7232916263657445\n",
    "# 1.4257850382841468\n",
    "# 0.926444086189883\n",
    "# 1.1553662804048155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:20:55.003104Z",
     "start_time": "2020-01-13T14:20:54.913028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42098025406751793\n",
      "1.0022769123840924\n",
      "\n",
      "1.1634973907282613\n",
      "1.003084790662937\n",
      "\n",
      "0.8652917291366509\n",
      "1.0101346504900341\n",
      "\n",
      "1.0325176442373727\n",
      "0.9977065743799649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in [0,1,2,3]:\n",
    "    print(score[meter].min())\n",
    "    print(weight[meter][score[meter].argmin()].sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:20:55.069110Z",
     "start_time": "2020-01-13T14:20:55.004742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0166223  0.         0.         0.2458813  0.         0.73977331]\n",
      "\n",
      "[0.25009516 0.         0.18585956 0.         0.         0.56713007]\n",
      "\n",
      "[0.         0.         0.         0.19816822 0.         0.81196643]\n",
      "\n",
      "[0.2170427  0.         0.19712148 0.         0.58354239 0.        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meter in [0,1,2,3]:\n",
    "#     for i in range(N):\n",
    "    print(weight[meter][score[meter].argmin()])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:20:55.116198Z",
     "start_time": "2020-01-13T14:20:55.070344Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_pred(test_sub, weight, N):\n",
    "    pred_new = list()\n",
    "    for meter in [0,1,2,3]:\n",
    "        test_sub_m = test_sub.query(f'meter=={meter}')\n",
    "        ensemble_m = sum([np.log1p(test_sub_m[f'pred{i+1}']) * weight[meter][score[meter].argmin()][i] for i in range(N)])\n",
    "        pred_new.append(ensemble_m)\n",
    "\n",
    "    pred_new = pd.concat(pred_new).sort_index()\n",
    "    return np.expm1(pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:08.282555Z",
     "start_time": "2020-01-13T14:20:55.118791Z"
    }
   },
   "outputs": [],
   "source": [
    "ensembled_pred1 = new_pred(test_sub, weight, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:13.569888Z",
     "start_time": "2020-01-13T14:21:08.284068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7855268527671803\n",
      "0.7664519155946278\n",
      "0.7759848514773457\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(np.log1p(test2018['leaked_meter_reading']), np.log1p(ensembled_pred1.loc[test2018.index]))))\n",
    "print(np.sqrt(mean_squared_error(np.log1p(test2017['leaked_meter_reading']), np.log1p(ensembled_pred1.loc[test2017.index]))))\n",
    "print(np.sqrt(mean_squared_error(np.log1p(test['leaked_meter_reading']), np.log1p(ensembled_pred1.loc[test.index]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:03:55.523123Z",
     "start_time": "2020-01-13T14:03:48.198885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7919666357312548\n",
      "0.7757227819125097\n",
      "0.7838330149095364\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(np.log1p(test2018['leaked_meter_reading']), np.log1p(ensembled_pred1.loc[test2018.index]))))\n",
    "print(np.sqrt(mean_squared_error(np.log1p(test2017['leaked_meter_reading']), np.log1p(ensembled_pred1.loc[test2017.index]))))\n",
    "print(np.sqrt(mean_squared_error(np.log1p(test['leaked_meter_reading']), np.log1p(ensembled_pred1.loc[test.index]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:13.573386Z",
     "start_time": "2020-01-13T14:21:13.571312Z"
    }
   },
   "outputs": [],
   "source": [
    "# 0.9455117442226527\n",
    "# 0.7985375584144594\n",
    "\n",
    "# 0.9404366275680945\n",
    "# 0.8062714386695903\n",
    "\n",
    "#0.9408301210841344\n",
    "#0.8029139931610979\n",
    "#all 0.8744504105324552\n",
    "\n",
    "# 0.9382531143644084\n",
    "# 0.8031481393084626\n",
    "# 0.873175711300433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:19.191764Z",
     "start_time": "2020-01-13T14:21:13.574547Z"
    }
   },
   "outputs": [],
   "source": [
    "new_submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:21:19.486175Z",
     "start_time": "2020-01-13T14:21:19.193560Z"
    }
   },
   "outputs": [],
   "source": [
    "new_submission['meter_reading'] = ensembled_pred1.values\n",
    "#                                       submission1['meter_reading'] * arr[arr[:,0].argmin()][1][0] \\\n",
    "#                                     + submission2['meter_reading'] * arr[arr[:,0].argmin()][1][1] \\\n",
    "#                                     + submission3['meter_reading'] * arr[arr[:,0].argmin()][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:23:12.149838Z",
     "start_time": "2020-01-13T14:21:19.487563Z"
    }
   },
   "outputs": [],
   "source": [
    "new_submission.to_csv('../output/submission_my_leak_validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-13T14:19:23.251615Z",
     "start_time": "2020-01-13T14:19:00.881Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
