{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T07:00:50.711245Z",
     "start_time": "2020-01-14T07:00:46.678337Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import _pickle as cPickle\n",
    "from copy import deepcopy\n",
    "from datetime import date, datetime, timedelta\n",
    "import japanize_matplotlib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T07:00:50.879203Z",
     "start_time": "2020-01-14T07:00:50.715328Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('../input/building_metadata.csv')\n",
    "weather_train = pd.read_csv('../input/weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:42:14.032623Z",
     "start_time": "2020-01-14T06:41:50.427874Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "train = train.merge(metadata,on='building_id',how = 'left')\n",
    "train = train.merge(weather_train,on=['site_id','timestamp'],how='left')\n",
    "\n",
    "leaked_df = pd.read_feather('../input/leak.feather')\n",
    "leaked_df['meter'] = leaked_df['meter'].astype(int)\n",
    "leaked_df = leaked_df.rename(columns={'meter_reading':'leaked_meter_reading'})\n",
    "\n",
    "dic = train[['building_id','site_id']]\n",
    "dic = dic.set_index('building_id').to_dict()\n",
    "dic = dic['site_id']\n",
    "\n",
    "leaked_df = leaked_df[leaked_df['leaked_meter_reading'].notnull()]\n",
    "leaked_df['site_id'] = leaked_df['building_id'].map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:42:14.987100Z",
     "start_time": "2020-01-14T06:42:14.037386Z"
    }
   },
   "outputs": [],
   "source": [
    "leaked_df = leaked_df.rename(columns={'leaked_meter_reading': 'meter_reading'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:42:14.999239Z",
     "start_time": "2020-01-14T06:42:14.995854Z"
    }
   },
   "outputs": [],
   "source": [
    "# leaked_df = pd.read_feather('../input/leak_data.feather')#.rename(columns={'meter_reading': 'leaked_meter_reading'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:43:02.915191Z",
     "start_time": "2020-01-14T06:42:15.002067Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 覚え書き\n",
    "# 連続で同じ値を取るやつを除去\n",
    "# ただし、同じ値を取るやつが最小値だった場合は除去しない(電気データの場合、最小値=休みの日とかの可能性があるため)\n",
    "\n",
    "del_list = list()\n",
    "\n",
    "for building_id in range(1449):\n",
    "    leaked_df_gb = leaked_df[leaked_df['building_id'] == building_id].groupby(\"meter\")\n",
    "\n",
    "    for meter, tmp_df in leaked_df_gb:\n",
    "#         print(\"building_id: {}, meter: {}\".format(building_id, meter))\n",
    "        data = tmp_df['meter_reading'].values\n",
    "#         splited_value = np.split(data, np.where((data[1:] != data[:-1]) | (data[1:] == min(data)))[0] + 1)\n",
    "#         splited_date = np.split(tmp_df.timestamp.values, np.where((data[1:] != data[:-1]) | (data[1:] == min(data)))[0] + 1)\n",
    "        splited_idx = np.split(tmp_df.index.values, np.where((data[1:] != data[:-1]) | (data[1:] == min(data)))[0] + 1)\n",
    "        for i, x in enumerate(splited_idx):\n",
    "            if len(x) > 24:\n",
    "#                 print(\"length: {},\\t{}-{},\\tvalue: {}\".format(len(x), x[0], x[-1], splited_value[i][0]))\n",
    "                del_list.extend(x[1:])\n",
    "                \n",
    "                \n",
    "#         print()\n",
    "\n",
    "del tmp_df, leaked_df_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:43:02.933532Z",
     "start_time": "2020-01-14T06:43:02.922772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134269"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(del_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:43:02.992992Z",
     "start_time": "2020-01-14T06:43:02.936824Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def idx_to_drop(df):\n",
    "#     drop_cols = []\n",
    "#     electric_zero = df[(df['meter']==0)&(df['meter_reading']==0)].index.values.tolist()\n",
    "#     drop_cols.extend(electric_zero)\n",
    "#     not_summer = df[(df['timestamp'].dt.month!=7)&(df['timestamp'].dt.month!=8)]\n",
    "#     not_summer['cumsum'] = not_summer.groupby(['building_id','meter'])['meter_reading'].cumsum()\n",
    "#     not_summer['shifted'] = not_summer.groupby(['building_id','meter'])['cumsum'].shift(48)\n",
    "#     not_summer['difference'] = not_summer['cumsum']-not_summer['shifted']\n",
    "#     steam_zero = not_summer[(not_summer['difference']==0) & (not_summer['meter']==2)].index.values.tolist()\n",
    "#     hotwater_zero = not_summer[(not_summer['difference']==0) & (not_summer['meter']==3)].index.values.tolist()\n",
    "#     drop_cols.extend(steam_zero)\n",
    "#     drop_cols.extend(hotwater_zero)\n",
    "#     del not_summer\n",
    "#     not_winter = leaked_df[(df['timestamp'].dt.month!=12)&(df['timestamp'].dt.month!=1)]\n",
    "#     not_winter['cumsum'] = not_winter.groupby(['building_id','meter'])['meter_reading'].cumsum()\n",
    "#     not_winter['shifted'] = not_winter.groupby(['building_id','meter'])['cumsum'].shift(48)\n",
    "#     not_winter['difference'] = not_winter['cumsum']-not_winter['shifted']\n",
    "#     chilled_zero = not_winter[(not_winter['difference']==0) & (not_winter['meter']==1)].index.values.tolist()\n",
    "#     drop_cols.extend(chilled_zero)\n",
    "#     return drop_cols\n",
    "\n",
    "# del_list.extend(idx_to_drop(leaked_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:43:04.198410Z",
     "start_time": "2020-01-14T06:43:02.995693Z"
    }
   },
   "outputs": [],
   "source": [
    "del_list_new = leaked_df.loc[del_list].index#query('timestamp < 20160901').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:43:05.837526Z",
     "start_time": "2020-01-14T06:43:04.200058Z"
    }
   },
   "outputs": [],
   "source": [
    "leaked_df = leaked_df.drop(del_list_new).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:43:10.020782Z",
     "start_time": "2020-01-14T06:43:05.839425Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../input/leak_data_drop_bad_rows.pkl', 'wb') as f:\n",
    "    pickle.dump(leaked_df,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
